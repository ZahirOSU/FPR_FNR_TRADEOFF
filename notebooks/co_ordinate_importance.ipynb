{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The importance of good co-ordinates when using MACEst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xe but this version of numpy is 0xd",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xe but this version of numpy is 0xd"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/8k/kjcv8fg107n9xl077vfg2_8m0000gn/T/ipykernel_92221/3942460940.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# import seaborn as sns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cs3600/lib/python3.8/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m \u001b[0m_check_versions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cs3600/lib/python3.8/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36m_check_versions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;31m# Quickfix to ensure Microsoft Visual C++ redistributable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;31m# DLLs are loaded before importing kiwisolver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mft2font\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     for modname, minver in [\n",
      "\u001b[0;31mImportError\u001b[0m: numpy.core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "\n",
    "# import seaborn as sns \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import log_loss, brier_score_loss\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import NeighborhoodComponentsAnalysis\n",
    "\n",
    "from macest.classification import models as clmod\n",
    "from macest.classification import plots as clplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.set_context(\"talk\")\n",
    "# sns.set_context(\"poster\")\n",
    "sns.set_context(\"notebook\")\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['lettr',\n",
    "'x-box',\n",
    "'y-box',\n",
    "'width',\n",
    "'high',\n",
    "'onpix',\n",
    "'x-bar',\n",
    "'y-bar',\n",
    "'x2bar',\n",
    "'y2bar',\n",
    "'xybar',\n",
    "'x2ybr',\n",
    "'xy2br',\n",
    "'x-ege',\n",
    "'xegvy',\n",
    "'y-ege',\n",
    "'yegvx']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The German Credit XGBoost model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6f9d55e2cd5792dc66d332ef3ccafde266046ce4",
    "id": "uOcS5s3VZKFq"
   },
   "source": [
    "The German Credit data set is a publically available data set downloaded from the UCI Machine Learning Repository. The data contains data on 20 variables and the classification whether an applicant is considered a Good or a Bad credit risk for 1000 loan applicants.\n",
    "\n",
    "#### [Data Source](https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data))\n",
    "- Professor Dr. Hans Hofmann  \n",
    "- Institut f\"ur Statistik und \"Okonometrie  \n",
    "- Universit\"at Hamburg  \n",
    "- FB Wirtschaftswissenschaften  \n",
    "- Von-Melle-Park 5    \n",
    "- 2000 Hamburg 13\n",
    "\n",
    "#### Benchmark\n",
    "![Credit Risk Classification: Faster Machine Learning with Intel Optimized Packages](https://i.imgur.com/nL1l7WI.png)\n",
    "\n",
    "according to [1] the best model is Random Forest with balanced feature selection data. it's has Accuracy 82%, Precision 84%, Recall 82% and F1-Score 81%. \n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "The goal of this kernel is to beat The benchmark with  :\n",
    "- Convert dataset to Machine Learning friendly (Feature Engginering)\n",
    "- Develop XGBoost model to predict whether a loan is a good or bad risk.\n",
    "- Find the Best parameter for XGBoost Model (Hyperparameter Tunning)\n",
    "- Beat the Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "86c6a56e4b0988d902401370b957f63f4f2754f1",
    "id": "oZH67UWnA915"
   },
   "source": [
    "### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fa1b3ac82eb8fe1b02d69fab3a10b621f1392484",
    "id": "UQUQbCn-LIjR",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Importing necessary packages in Python \n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import numpy as np ; np.random.seed(sum(map(ord, \"aesthetics\")))\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import make_classification \n",
    "from sklearn.model_selection import learning_curve\n",
    "#from sklearn.cross_validation import train_test_split \n",
    "#from sklearn.grid_search import GridSearchCV\n",
    "#from sklearn.cross_validation import ShuffleSplit\n",
    "from sklearn.metrics import classification_report,confusion_matrix, roc_curve, roc_auc_score, auc, accuracy_score\n",
    "from sklearn.model_selection import ShuffleSplit,train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, label_binarize, StandardScaler, MinMaxScaler\n",
    "\n",
    "import seaborn \n",
    "seaborn.set_context('notebook') \n",
    "seaborn.set_style(style='darkgrid')\n",
    "\n",
    "from pprint import pprint \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e53977fea8ba2969bb815820b810ae0798f79ff3",
    "id": "HvfBj0KiBC1m"
   },
   "source": [
    "### Evaluation Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ad532098b4568aab69e710aa1b73097b0aeaa56a",
    "id": "Y5FAGSW_K_il",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Function for evaluation reports\n",
    "def get_eval1(clf, X,y):\n",
    "    # Cross Validation to test and anticipate overfitting problem\n",
    "    scores1 = cross_val_score(clf, X, y, cv=2, scoring='accuracy')\n",
    "    scores2 = cross_val_score(clf, X, y, cv=2, scoring='precision')\n",
    "    scores3 = cross_val_score(clf, X, y, cv=2, scoring='recall')\n",
    "    scores4 = cross_val_score(clf, X, y, cv=2, scoring='roc_auc')\n",
    "    \n",
    "    # The mean score and standard deviation of the score estimate\n",
    "    print(\"Cross Validation Accuracy: %0.2f (+/- %0.2f)\" % (scores1.mean(), scores1.std()))\n",
    "    print(\"Cross Validation Precision: %0.2f (+/- %0.2f)\" % (scores2.mean(), scores2.std()))\n",
    "    print(\"Cross Validation Recall: %0.2f (+/- %0.2f)\" % (scores3.mean(), scores3.std()))\n",
    "    print(\"Cross Validation roc_auc: %0.2f (+/- %0.2f)\" % (scores4.mean(), scores4.std()))\n",
    "    \n",
    "    return \n",
    "\n",
    "def get_eval2(clf, X_train, y_train,X_test, y_test):\n",
    "    # Cross Validation to test and anticipate overfitting problem\n",
    "    scores1 = cross_val_score(clf, X_test, y_test, cv=2, scoring='accuracy')\n",
    "    scores2 = cross_val_score(clf, X_test, y_test, cv=2, scoring='precision')\n",
    "    scores3 = cross_val_score(clf, X_test, y_test, cv=2, scoring='recall')\n",
    "    scores4 = cross_val_score(clf, X_test, y_test, cv=2, scoring='roc_auc')\n",
    "    \n",
    "    # The mean score and standard deviation of the score estimate\n",
    "    print(\"Cross Validation Accuracy: %0.2f (+/- %0.2f)\" % (scores1.mean(), scores1.std()))\n",
    "    print(\"Cross Validation Precision: %0.2f (+/- %0.2f)\" % (scores2.mean(), scores2.std()))\n",
    "    print(\"Cross Validation Recall: %0.2f (+/- %0.2f)\" % (scores3.mean(), scores3.std()))\n",
    "    print(\"Cross Validation roc_auc: %0.2f (+/- %0.2f)\" % (scores4.mean(), scores4.std()))\n",
    "    \n",
    "    return  \n",
    "  \n",
    "# Function to get roc curve\n",
    "def get_roc (y_test,y_pred):\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    #Plot of a ROC curve\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(fpr, tpr, color='darkorange',\n",
    "             label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.show()\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "148a2b3cfebaac7674b5bb78496d1cf0266a26cf",
    "id": "ktQtae8aBGPQ"
   },
   "source": [
    "### XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a7b80d642ccc18e23b9a0ece9c7f57eca3c67cfd",
    "id": "qOM2Y0A8CGN8",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "#print('XGBoost v',xgb.__version__)\n",
    "\n",
    "# fit, train and cross validate Decision Tree with training and test data \n",
    "def xgbclf(params, X_train, y_train,X_test, y_test):\n",
    "  \n",
    "    eval_set=[(X_train, y_train), (X_test, y_test)]\n",
    "    \n",
    "    model = XGBClassifier(**params).\\\n",
    "      fit(X_train, y_train, eval_set=eval_set, \\\n",
    "                  eval_metric='auc', early_stopping_rounds = 100, verbose=100)\n",
    "        \n",
    "    #print(model.best_ntree_limit)\n",
    "\n",
    "    model.set_params(**{'n_estimators': model.best_ntree_limit})\n",
    "    model.fit(X_train, y_train)\n",
    "    #print(model,'\\n')\n",
    "    \n",
    "    # Predict target variables y for test data\n",
    "    y_pred = model.predict(X_test, ntree_limit=model.best_ntree_limit) #model.best_iteration\n",
    "    #print(y_pred)\n",
    "   \n",
    "    # Get Cross Validation and Confusion matrix\n",
    "    #get_eval(model, X_train, y_train)\n",
    "    #get_eval2(model, X_train, y_train,X_test, y_test)\n",
    "    \n",
    "    # Create and print confusion matrix    \n",
    "    abclf_cm = confusion_matrix(y_test,y_pred)\n",
    "    print(abclf_cm)\n",
    "    \n",
    "    #y_pred = model.predict(X_test)\n",
    "    print (classification_report(y_test,y_pred) )\n",
    "    print ('\\n')\n",
    "    print (\"Model Final Generalization Accuracy: %.6f\" %accuracy_score(y_test,y_pred) )\n",
    "    \n",
    "    # Predict probabilities target variables y for test data\n",
    "    y_pred_proba = model.predict_proba(X_test, ntree_limit=model.best_ntree_limit)[:,1] #model.best_iteration\n",
    "    get_roc (y_test,y_pred_proba)\n",
    "    return model\n",
    "\n",
    "def plot_featureImportance(model, keys):\n",
    "  importances = model.feature_importances_\n",
    "\n",
    "  importance_frame = pd.DataFrame({'Importance': list(importances), 'Feature': list(keys)})\n",
    "  importance_frame.sort_values(by = 'Importance', inplace = True)\n",
    "  importance_frame.tail(10).plot(kind = 'barh', x = 'Feature', figsize = (8,8), color = 'orange')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2e8d5ce5e9daf39d851ca53856f640a90156745a",
    "id": "b9VmiiUDCvRV"
   },
   "source": [
    "### Preprocess\n",
    "- Importing Dataset\n",
    "- StandardScaler\n",
    "- Encoding Categorical Feature\n",
    "- Concate Transformed Dataset\n",
    "- Split Training Dataset\n",
    "- XGBoost  1a: Unbalance Dataset (Base Model: ROC_AUC:0.74)\n",
    "- XGBoost  1b: Unbalance Dataset (ROC_AUC:0.79)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "366cfb21b371f12c5bbf005342de219717fde974",
    "id": "L4G0iMwfKb4J"
   },
   "source": [
    "### Import Dataset\n",
    "\n",
    "OK let's get started. We'll download the data from the UCI website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4807a2a54ddeb7ecb9142b586088ea672103d4ff",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 498
    },
    "id": "YYgBTbPj1fbQ",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "ee90853d-6701-418a-ca9c-b67eb4a59109"
   },
   "outputs": [],
   "source": [
    "url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data\"\n",
    "\n",
    "names = ['existingchecking', 'duration', 'credithistory', 'purpose', 'creditamount', \n",
    "         'savings', 'employmentsince', 'installmentrate', 'statussex', 'otherdebtors', \n",
    "         'residencesince', 'property', 'age', 'otherinstallmentplans', 'housing', \n",
    "         'existingcredits', 'job', 'peopleliable', 'telephone', 'foreignworker', 'classification']\n",
    "\n",
    "data = pd.read_csv(url, names = names, delimiter=' ')\n",
    "print(data.shape)\n",
    "print (data.columns)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "224c2c3967abdccd1e4527c18024e08288ba1ca9",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B3FPJfz33xkK",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "abc0fc15-193c-4c1f-9fe3-c19fb34081e4"
   },
   "outputs": [],
   "source": [
    "# Binarize the y output for easier use of e.g. ROC curves -> 0 = 'bad' credit; 1 = 'good' credit\n",
    "data.classification.replace([1,2], [1,0], inplace=True)\n",
    "# Print number of 'good' credits (should be 700) and 'bad credits (should be 300)\n",
    "data.classification.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2d2774790c3f63cfc0eaa81517ce8f0eb4680478",
    "id": "Tr1A8ZIHzuFw"
   },
   "source": [
    "### StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f03a76714ee08fe41f9b59aab287d68d481892b5",
    "id": "dKKUEqTo380x",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#numerical variables labels\n",
    "numvars = ['creditamount', 'duration', 'installmentrate', 'residencesince', 'age', \n",
    "           'existingcredits', 'peopleliable', 'classification']\n",
    "\n",
    "# Standardization\n",
    "numdata_std = pd.DataFrame(StandardScaler().fit_transform(data[numvars].drop(['classification'], axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "19dce81fc16194265c5d8942fa81c64934d60855",
    "id": "X4ZzfmRy4M9I"
   },
   "source": [
    "### Encoding Categorical Feature\n",
    "\n",
    "Labelencoding to transform categorical to numerical, Enables better Visualization than one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dab67695a0984af965a7dbea250276c4369b5875",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xSnUU8E_4IgX",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "b97741fc-a400-429b-e612-eaa6534ff221"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "#categorical variables labels\n",
    "catvars = ['existingchecking', 'credithistory', 'purpose', 'savings', 'employmentsince',\n",
    "           'statussex', 'otherdebtors', 'property', 'otherinstallmentplans', 'housing', 'job', \n",
    "           'telephone', 'foreignworker']\n",
    "\n",
    "d = defaultdict(LabelEncoder)\n",
    "\n",
    "# Encoding the variable\n",
    "lecatdata = data[catvars].apply(lambda x: d[x.name].fit_transform(x))\n",
    "\n",
    "# print transformations\n",
    "for x in range(len(catvars)):\n",
    "    print(catvars[x],\": \", data[catvars[x]].unique())\n",
    "    print(catvars[x],\": \", lecatdata[catvars[x]].unique())\n",
    "\n",
    "#One hot encoding, create dummy variables for every category of every categorical variable\n",
    "dummyvars = pd.get_dummies(data[catvars])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6a15498bdd45a6b2d0c88edbe3059744294396c6",
    "id": "R3OBrifU4Zpb"
   },
   "source": [
    "### Concate Transformed Dataset\n",
    "append the dummy variable of the initial numerical variables numvars# append "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "50738e0e4b89a8facc7c73581661f3110427d8e9",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jkncbC1M4ZzD",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "8c2ec46b-2b46-48e6-cf06-e5b40a5270c2"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/8k/kjcv8fg107n9xl077vfg2_8m0000gn/T/ipykernel_92221/325652921.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_clean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumvars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummyvars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_clean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data_clean = pd.concat([data[numvars], dummyvars], axis = 1)\n",
    "\n",
    "print(data_clean.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "53f8db9397eeb56dae3d735e712b4ba251a36a7b",
    "id": "OI89YwDN4kXI"
   },
   "source": [
    "### Split Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_clean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/8k/kjcv8fg107n9xl077vfg2_8m0000gn/T/ipykernel_92221/2340283838.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Unscaled, unnormalized data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_clean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_clean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'classification'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_clean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_clean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'classification'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# X,y = datasets.make_circles(n_samples= 10**4, noise = 0.4, factor =10**-1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_clean' is not defined"
     ]
    }
   ],
   "source": [
    "# Unscaled, unnormalized data\n",
    "X_clean = data_clean.drop('classification', axis=1)\n",
    "y_clean = data_clean['classification']\n",
    "# X,y = datasets.make_circles(n_samples= 10**4, noise = 0.4, factor =10**-1)\n",
    "\n",
    "X_train, X_conf_train, y_train, y_conf_train  = train_test_split(X_clean, y_clean, \n",
    "                                                                 test_size=0.6, random_state=10)\n",
    "\n",
    "X_conf_train, X_cal, y_conf_train, y_cal = train_test_split(X_conf_train, y_conf_train,\n",
    "                                                            test_size=0.5, random_state=0)\n",
    "\n",
    "X_cal, X_test, y_cal,  y_test, = train_test_split(X_cal, y_cal, \n",
    "                                                  test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/8k/kjcv8fg107n9xl077vfg2_8m0000gn/T/ipykernel_92221/2909654248.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'X_train, y_train:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'X_test, y_test:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'X_conf_train, y_conf_train:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_conf_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_conf_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'X_cal, y_cal:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_cal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_cal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "print('X_train, y_train:', np.shape(X_train), np.shape(y_train))\n",
    "print('X_test, y_test:', np.shape(X_test), np.shape(y_test))\n",
    "\n",
    "print('X_conf_train, y_conf_train:', np.shape(X_conf_train), np.shape(y_conf_train))\n",
    "print('X_cal, y_cal:', np.shape(X_cal), np.shape(y_cal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "10ebb57456ac4233b77b1ad284c15984aee73a1c",
    "id": "ylrlLjs8bX_k"
   },
   "source": [
    "### XGBoost  Training (ROC_AUC:0.79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9b27e5641d57347d244ebc33a634c35a3a8e0947",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 845
    },
    "id": "BSTCnez0bX_k",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "102e17d2-d0ca-49eb-945c-f9143b861b5b"
   },
   "outputs": [],
   "source": [
    "params2={\n",
    "    'n_estimators':3000,\n",
    "    'objective': 'binary:logistic',\n",
    "    'learning_rate': 0.005,\n",
    "    #'gamma':0.01,\n",
    "    'subsample':0.555,\n",
    "    'colsample_bytree':0.7,\n",
    "    'min_child_weight':3,\n",
    "    'max_depth':8,\n",
    "    #'seed':1024,\n",
    "    'n_jobs' : -1\n",
    "}\n",
    "\n",
    "# xgbclf(params2, X_pp_train, y_pp_train, X_test, y_test)\n",
    "# xgbclf(params2, X_train_clean, y_train_clean, X_test_clean, y_test_clean)\n",
    "model = xgbclf(params2, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.score(X_conf_train, y_conf_train))\n",
    "print(model.score(X_cal, y_cal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MACest Confidence Model For The German Credit XGBoost model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training MACEst model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from macest.classification import models as clmod\n",
    "from macest.classification import plots as clplot\n",
    "\n",
    "param_bounds = clmod.SearchBounds(alpha_bounds = (0, 500), k_bounds = (5,15))\n",
    "neighbour_search_params = clmod.HnswGraphArgs(query_args = dict(ef = 1100))\n",
    "\n",
    "macest_model = clmod.ModelWithConfidence(model,\n",
    "                                       X_conf_train,\n",
    "                                       y_conf_train)\n",
    "\n",
    "macest_model.fit(X_cal, np.array(y_cal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We can change the MACEst defaults if we want as shown below by editing the NamedTuple for each parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clmod.SearchBounds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clmod.HnswGraphArgs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimiser args are the arguments passed to scipy differential evolution and must be passed as a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser_args = dict(popsize = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_bounds = clmod.SearchBounds(k_bounds = (3,50))\n",
    "# neighbour_search_params = clmod.HnswGraphArgs(query_args = dict(ef = 1100), \n",
    "#                                               init_args = dict(method = 'hnsw', space = 'cosinesimil'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_bounds = clmod.SearchBounds(k_bounds = (5,50))\n",
    "neighbour_search_params = clmod.HnswGraphArgs(query_args = dict(ef = 1000))\n",
    "optimiser_args = dict(popsize = 25, disp = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macest_model = clmod.ModelWithConfidence(model,\n",
    "                                      X_conf_train,\n",
    "                                      y_conf_train, \n",
    "                                      search_method_args =neighbour_search_params)\n",
    "\n",
    "macest_model.fit(X_cal,\n",
    "               np.array(y_cal),\n",
    "               param_range = param_bounds,\n",
    "               optimiser_args = optimiser_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macest_model.macest_model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macest_model.__dir__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_preds = model.predict(X_test)\n",
    "macest_conf_preds = macest_model.predict_proba(X_test)\n",
    "xgboost_conf_preds = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_conf_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macest_conf_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macest_point_prediction_conf = macest_model.predict_confidence_of_point_prediction(X_test) \n",
    "                              \n",
    "xgboost_point_prediction_conf = np.amax(xgboost_conf_preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macest_point_prediction_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_point_prediction_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clplot.plot_calibration_curve([xgboost_point_prediction_conf,\n",
    "                               macest_point_prediction_conf], \n",
    "                              ['XGBoost', 'MACE'],\n",
    "                              xgboost_preds,\n",
    "                              y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Let's compare calibration and forecast metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clplot.plot_calibration_metrics([xgboost_point_prediction_conf, \n",
    "                                macest_point_prediction_conf], \n",
    "                              ['XGBoost','MACE'], xgboost_preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clplot.plot_forecast_metrics([xgboost_point_prediction_conf, \n",
    "                                macest_point_prediction_conf], \n",
    "                              ['XGBoost','MACE'], xgboost_preds, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FPR_FNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will try to add confidence to a classic ML challenge, classifying images of letters based upon some statistical attributes (https://archive.ics.uci.edu/ml/datasets/letter+recognition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running this stage, please download the `letters.data` file from the above URL and place this within the `data` folder in the root directory of this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters_df = pd.read_csv(\"../../data/letter-recognition.data\", header=None, names=cols).sample(frac=1)\n",
    "letters_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = letters_df['lettr']\n",
    "X = letters_df.drop('lettr', axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the original feature space we have lots of correlated variables, and the feature importance is unlikely to be even amongst all of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,10))\n",
    "sns.heatmap(X.corr(),\n",
    "            cmap = 'coolwarm',\n",
    "            annot = True,\n",
    "            vmin = -1.1, vmax =1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X/16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = LabelEncoder()\n",
    "y_clean = enc.fit_transform(y_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pp_train, X_conf_train, y_pp_train, y_conf_train  = train_test_split(X_clean, y_clean, test_size=0.66, random_state=0)\n",
    "\n",
    "X_conf_train, X_cal, y_conf_train, y_cal = train_test_split(X_conf_train, y_conf_train,\n",
    "                                                            test_size=0.4, random_state=0)\n",
    "X_cal, X_test, y_cal,  y_test, = train_test_split(X_cal, y_cal, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_pp_train.shape[0])\n",
    "print(X_conf_train.shape[0])\n",
    "print(X_cal.shape[0])\n",
    "print(X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state =0,\n",
    "                               n_estimators =800,\n",
    "                               n_jobs =-1)\n",
    "model.fit(X_pp_train, y_pp_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.score(X_pp_train, y_pp_train))\n",
    "print(model.score(X_conf_train, y_conf_train))\n",
    "print(model.score(X_cal, y_cal))\n",
    "print(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will use the L2 metric, this is implictly saying that our measure of similarity between data points is the euclidean distance in feature space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_bounds = clmod.SearchBounds(k_bounds = (3,50))\n",
    "neighbour_search_params = clmod.HnswGraphArgs(query_args = dict(ef = 1000))\n",
    "optimiser_args = dict(popsize = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "macest_model = clmod.ModelWithConfidence(model,\n",
    "                                      X_conf_train,\n",
    "                                      y_conf_train, \n",
    "                                      search_method_args = neighbour_search_params)\n",
    "\n",
    "macest_model.fit(X_cal, y_cal, param_range = param_bounds, optimiser_args= optimiser_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test)\n",
    "conf_preds = macest_model.predict_proba(X_test)\n",
    "rf_conf = model.predict_proba(X_test)\n",
    "rf_point_prediction_conf = np.amax(rf_conf, axis=1)\n",
    "macest_point_prediction_conf = macest_model.predict_confidence_of_point_prediction(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clplot.plot_calibration_curve([rf_point_prediction_conf,\n",
    "                              macest_point_prediction_conf], \n",
    "                              ['Uncalibrated RF','MACEst' ],\n",
    "                              preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clplot.plot_quantile_spaced_calibration_curve([rf_point_prediction_conf,\n",
    "                             macest_point_prediction_conf,\n",
    "                                ], \n",
    "                              ['Uncalibrated RF','MACEst' ],\n",
    "                              preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clplot.plot_calibration_metrics([rf_point_prediction_conf,\n",
    "                             macest_point_prediction_conf,\n",
    "                                ], \n",
    "                              ['Uncalibrated RF','MACEst' ],\n",
    "                              preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clplot.plot_forecast_metrics([rf_point_prediction_conf,\n",
    "                             macest_point_prediction_conf], \n",
    "                              ['Uncalibrated RF','MACEst' ],\n",
    "                              preds, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that MACEst performs better than the raw estimates from the random forest however it's still not great, let's try inducing a better co-ordinate system "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pp_train, X_conf_train, y_pp_train, y_conf_train  = train_test_split(X, y, test_size=0.66, random_state=0)\n",
    "\n",
    "pca = PCA(n_components=0.95, whiten = True)\n",
    "pca.fit(X_pp_train)\n",
    "\n",
    "X_pp_train = pca.transform(X_pp_train)\n",
    "X_conf_train = pca.transform(X_conf_train)\n",
    "\n",
    "X_conf_train, X_cal, y_conf_train, y_cal = train_test_split(X_conf_train, y_conf_train,\n",
    "                                                            test_size=0.4, random_state=0)\n",
    "X_cal, X_test, y_cal,  y_test, = train_test_split(X_cal, y_cal, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state =0,\n",
    "                               n_estimators =800,\n",
    "                               n_jobs =-1)\n",
    "model.fit(X_pp_train, y_pp_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.score(X_pp_train, y_pp_train))\n",
    "print(model.score(X_conf_train, y_conf_train))\n",
    "print(model.score(X_cal, y_cal))\n",
    "print(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are now saying points are similar if the euclidean distance between their projection is whitned pca space (similar to mahalanobis) is small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbour_search_params = clmod.HnswGraphArgs(init_args = dict(method = 'hnsw',\n",
    "                                                               space = 'l2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macest_model = clmod.ModelWithConfidence(model,\n",
    "                                      X_conf_train,\n",
    "                                      y_conf_train, \n",
    "                                      search_method_args = neighbour_search_params)\n",
    "\n",
    "macest_model.fit(X_cal, y_cal, param_range = param_bounds, optimiser_args= optimiser_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test)\n",
    "conf_preds = macest_model.predict_proba(X_test)\n",
    "rf_conf = model.predict_proba(X_test)\n",
    "rf_point_prediction_conf = np.amax(rf_conf, axis=1)\n",
    "macest_point_prediction_conf = macest_model.predict_confidence_of_point_prediction(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clplot.plot_calibration_curve([rf_point_prediction_conf,macest_point_prediction_conf], \n",
    "                              ['Uncalibrated RF','MACEst' ],\n",
    "                              preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clplot.plot_quantile_spaced_calibration_curve([rf_point_prediction_conf, macest_point_prediction_conf], \n",
    "                                              ['Uncalibrated RF','MACEst' ],\n",
    "                                              preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clplot.plot_calibration_metrics([rf_point_prediction_conf, macest_point_prediction_conf], \n",
    "                                 ['Uncalibrated RF','MACEst' ],\n",
    "                                 preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clplot.plot_forecast_metrics([rf_point_prediction_conf,\n",
    "                             macest_point_prediction_conf,], \n",
    "                              ['Uncalibrated RF','MACEst' ],\n",
    "                              preds, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## That is better but still not great, can we do better ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MACEst works by finding a set of nearest neighbours and then uses the distance to these k neighbours as a proxy for the epistemic uncertainty, because of this paradigm the natural metric to one which induces a good nearest neighbour distance. This method exists and is known as neighbourhood component analysis (https://www.cs.toronto.edu/~hinton/absps/nca.pdf)\n",
    "#### Let's compare the results if we use this metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pp_train, X_conf_train, y_pp_train, y_conf_train  = train_test_split(X, y, test_size=0.66, random_state=0)\n",
    "\n",
    "nca = NeighborhoodComponentsAnalysis(n_components = X_pp_train.shape[1] ,\n",
    "                                     max_iter = 30,\n",
    "                                     verbose =1)\n",
    "nca.fit(X_pp_train, y_pp_train)\n",
    "\n",
    "X_pp_train = nca.transform(X_pp_train)\n",
    "X_conf_train = nca.transform(X_conf_train)\n",
    "\n",
    "X_conf_train, X_cal, y_conf_train, y_cal = train_test_split(X_conf_train, y_conf_train,\n",
    "                                                            test_size=0.4, random_state=0)\n",
    "X_cal, X_test, y_cal,  y_test, = train_test_split(X_cal, y_cal, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state =0,\n",
    "                               n_estimators =800,\n",
    "                               n_jobs =-1)\n",
    "model.fit(X_pp_train, y_pp_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macest_model = clmod.ModelWithConfidence(model,\n",
    "                                      X_conf_train,\n",
    "                                      y_conf_train, \n",
    "                                      search_method_args = neighbour_search_params)\n",
    "\n",
    "macest_model.fit(X_cal, y_cal, param_range = param_bounds, optimiser_args= optimiser_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.score(X_pp_train, y_pp_train))\n",
    "print(model.score(X_conf_train, y_conf_train))\n",
    "print(model.score(X_cal, y_cal))\n",
    "print(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test)\n",
    "conf_preds = macest_model.predict_proba(X_test)\n",
    "rf_conf = model.predict_proba(X_test)\n",
    "rf_point_prediction_conf = np.amax(rf_conf, axis=1)\n",
    "macest_point_prediction_conf = macest_model.predict_confidence_of_point_prediction(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clplot.plot_calibration_curve([rf_point_prediction_conf,\n",
    "                              macest_point_prediction_conf,], \n",
    "                              ['Uncalibrated RF','MACEst' ],\n",
    "                              preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clplot.plot_quantile_spaced_calibration_curve([rf_point_prediction_conf, macest_point_prediction_conf], \n",
    "                                              ['Uncalibrated RF', 'MACEst'],\n",
    "                                              preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clplot.plot_calibration_metrics([rf_point_prediction_conf,\n",
    "                                 macest_point_prediction_conf], \n",
    "                                 ['Uncalibrated RF','MACEst' ],\n",
    "                                 preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clplot.plot_forecast_metrics([rf_point_prediction_conf,\n",
    "                              macest_point_prediction_conf,], \n",
    "                              ['Uncalibrated RF','MACEst' ],\n",
    "                              preds, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this metric we see that MACEst works very well"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (cs3600)",
   "language": "python",
   "name": "pycharm-8f6c722"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
